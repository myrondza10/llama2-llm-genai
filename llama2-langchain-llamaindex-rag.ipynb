{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6603928,"sourceType":"datasetVersion","datasetId":3810072},{"sourceId":6604037,"sourceType":"datasetVersion","datasetId":3810148},{"sourceId":7024184,"sourceType":"datasetVersion","datasetId":4039391},{"sourceId":2286,"sourceType":"datasetVersion","datasetId":1275}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"1ff6c71bfb1646ad9ea16cbbb15b0cec":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0e58fd536c5e4f39bc7bc6864d35e8cd","IPY_MODEL_b958fb7493334369b054c07caf079c78","IPY_MODEL_e2f3fa52a97c4d47b844d4beeb07f5d7"],"layout":"IPY_MODEL_2e01b10346284803911b58a7c2843263"}},"0e58fd536c5e4f39bc7bc6864d35e8cd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_433b82e419bc4b36827aa332b7a617aa","placeholder":"​","style":"IPY_MODEL_e887d4b3d1d74494b69d7146dae23699","value":"Loading checkpoint shards: 100%"}},"b958fb7493334369b054c07caf079c78":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_92abf8bac06a48c7a8223b0b649ede7e","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_13e01743be3141e0872659bf16b39e1f","value":2}},"e2f3fa52a97c4d47b844d4beeb07f5d7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6fd6ee183e9e4d8995db48e2a1f0b947","placeholder":"​","style":"IPY_MODEL_dfb79aec839d45d8bdf817f78047d153","value":" 2/2 [01:08&lt;00:00, 31.42s/it]"}},"2e01b10346284803911b58a7c2843263":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"433b82e419bc4b36827aa332b7a617aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e887d4b3d1d74494b69d7146dae23699":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"92abf8bac06a48c7a8223b0b649ede7e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13e01743be3141e0872659bf16b39e1f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6fd6ee183e9e4d8995db48e2a1f0b947":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dfb79aec839d45d8bdf817f78047d153":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Install Required Libraries & Packages","metadata":{}},{"cell_type":"code","source":"pip install transformers==4.31.0 accelerate==0.21.0 einops==0.6.1 langchain==0.0.240 xformers==0.0.20 bitsandbytes==0.41.0 peft safetensors sentencepiece streamlit langchain sentence-transformers gradio pypdf chromadb==0.4.15 pypdfium2","metadata":{"id":"sGD-5x9-NT7P","outputId":"598647da-e595-4512-d513-02b7a48cdcac","execution":{"iopub.status.busy":"2023-11-22T18:19:03.348903Z","iopub.execute_input":"2023-11-22T18:19:03.349543Z","iopub.status.idle":"2023-11-22T18:22:32.421592Z","shell.execute_reply.started":"2023-11-22T18:19:03.349510Z","shell.execute_reply":"2023-11-22T18:22:32.420304Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting transformers==4.31.0\n  Obtaining dependency information for transformers==4.31.0 from https://files.pythonhosted.org/packages/21/02/ae8e595f45b6c8edee07913892b3b41f5f5f273962ad98851dc6a564bbb9/transformers-4.31.0-py3-none-any.whl.metadata\n  Downloading transformers-4.31.0-py3-none-any.whl.metadata (116 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.9/116.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting accelerate==0.21.0\n  Obtaining dependency information for accelerate==0.21.0 from https://files.pythonhosted.org/packages/70/f9/c381bcdd0c3829d723aa14eec8e75c6c377b4ca61ec68b8093d9f35fc7a7/accelerate-0.21.0-py3-none-any.whl.metadata\n  Downloading accelerate-0.21.0-py3-none-any.whl.metadata (17 kB)\nCollecting einops==0.6.1\n  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting langchain==0.0.240\n  Obtaining dependency information for langchain==0.0.240 from https://files.pythonhosted.org/packages/59/d0/074f7fbd7323623cca4175e0323c2cff565d5cf8c6b58f5dc81f046aa29f/langchain-0.0.240-py3-none-any.whl.metadata\n  Downloading langchain-0.0.240-py3-none-any.whl.metadata (14 kB)\nCollecting xformers==0.0.20\n  Obtaining dependency information for xformers==0.0.20 from https://files.pythonhosted.org/packages/4b/b0/dfbb3b0ceafdb73cd1b2bbe33f65dc1c5c47dcb0d4b03ba6f95da6557306/xformers-0.0.20-cp310-cp310-manylinux2014_x86_64.whl.metadata\n  Downloading xformers-0.0.20-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.1 kB)\nCollecting bitsandbytes==0.41.0\n  Obtaining dependency information for bitsandbytes==0.41.0 from https://files.pythonhosted.org/packages/b9/33/1cea2d1c909dd3e2b595f7b73c4417f3786c385a4b269a5c40c7699bb14b/bitsandbytes-0.41.0-py3-none-any.whl.metadata\n  Downloading bitsandbytes-0.41.0-py3-none-any.whl.metadata (9.8 kB)\nCollecting peft\n  Obtaining dependency information for peft from https://files.pythonhosted.org/packages/14/0b/8402305043884c76a9d98e5e924c3f2211c75b02acd5b742e6c45d70506d/peft-0.6.2-py3-none-any.whl.metadata\n  Downloading peft-0.6.2-py3-none-any.whl.metadata (23 kB)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (0.4.0)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.1.99)\nCollecting streamlit\n  Obtaining dependency information for streamlit from https://files.pythonhosted.org/packages/9d/9f/09fe6469e891031596872bd50bff90d47bea5c32d426235714cf24662740/streamlit-1.28.2-py2.py3-none-any.whl.metadata\n  Downloading streamlit-1.28.2-py2.py3-none-any.whl.metadata (8.1 kB)\nCollecting sentence-transformers\n  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting gradio\n  Obtaining dependency information for gradio from https://files.pythonhosted.org/packages/cf/b5/a5165dcf589a6c301f8bae33510855a57ae62102152d03dff1c3f72b03c4/gradio-4.5.0-py3-none-any.whl.metadata\n  Downloading gradio-4.5.0-py3-none-any.whl.metadata (17 kB)\nRequirement already satisfied: pypdf in /opt/conda/lib/python3.10/site-packages (3.17.0)\nCollecting chromadb==0.4.15\n  Obtaining dependency information for chromadb==0.4.15 from https://files.pythonhosted.org/packages/f1/2a/549be867b5ab45112aacd9d113af788768a015e9e6d0ade831b45c1df877/chromadb-0.4.15-py3-none-any.whl.metadata\n  Downloading chromadb-0.4.15-py3-none-any.whl.metadata (7.2 kB)\nCollecting pypdfium2\n  Obtaining dependency information for pypdfium2 from https://files.pythonhosted.org/packages/64/a1/8e9f4c5ace3bc19cd6d9d0dedbfae0bc01e701e861e4de4e1a7f8bdf0533/pypdfium2-4.24.0-py3-none-manylinux_2_17_x86_64.whl.metadata\n  Downloading pypdfium2-4.24.0-py3-none-manylinux_2_17_x86_64.whl.metadata (45 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.6/45.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.31.0) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.31.0) (0.17.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.31.0) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.31.0) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.31.0) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.31.0) (2023.8.8)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.31.0) (2.31.0)\nCollecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.31.0)\n  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.31.0) (4.66.1)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate==0.21.0) (5.9.3)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.21.0) (2.0.0)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.240) (2.0.20)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.240) (3.8.5)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.240) (4.0.3)\nCollecting dataclasses-json<0.6.0,>=0.5.7 (from langchain==0.0.240)\n  Obtaining dependency information for dataclasses-json<0.6.0,>=0.5.7 from https://files.pythonhosted.org/packages/97/5f/e7cc90f36152810cab08b6c9c1125e8bcb9d76f8b3018d101b5f877b386c/dataclasses_json-0.5.14-py3-none-any.whl.metadata\n  Downloading dataclasses_json-0.5.14-py3-none-any.whl.metadata (22 kB)\nCollecting langsmith<0.1.0,>=0.0.11 (from langchain==0.0.240)\n  Obtaining dependency information for langsmith<0.1.0,>=0.0.11 from https://files.pythonhosted.org/packages/84/9e/208314830d8c523dae4dec41ab5aeeb2d42dc1667bbc3ff8b875244b3012/langsmith-0.0.66-py3-none-any.whl.metadata\n  Downloading langsmith-0.0.66-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: numexpr<3.0.0,>=2.8.4 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.240) (2.8.7)\nCollecting openapi-schema-pydantic<2.0,>=1.2 (from langchain==0.0.240)\n  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pydantic<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.240) (1.10.12)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.240) (8.2.3)\nCollecting pyre-extensions==0.0.29 (from xformers==0.0.20)\n  Downloading pyre_extensions-0.0.29-py3-none-any.whl (12 kB)\nCollecting torch>=1.10.0 (from accelerate==0.21.0)\n  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting chroma-hnswlib==0.7.3 (from chromadb==0.4.15)\n  Obtaining dependency information for chroma-hnswlib==0.7.3 from https://files.pythonhosted.org/packages/2f/48/f7609a3cb15a24c5d8ec18911ce10ac94144e9a89584f0a86bf9871b024c/chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\nRequirement already satisfied: fastapi>=0.95.2 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.15) (0.101.1)\nRequirement already satisfied: uvicorn[standard]>=0.18.3 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.15) (0.23.2)\nCollecting posthog>=2.4.0 (from chromadb==0.4.15)\n  Obtaining dependency information for posthog>=2.4.0 from https://files.pythonhosted.org/packages/a7/73/35758818228c70348be4c3c66a76653c62e894e0e3c3461453c5341ca926/posthog-3.0.2-py2.py3-none-any.whl.metadata\n  Downloading posthog-3.0.2-py2.py3-none-any.whl.metadata (2.0 kB)\nRequirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.15) (4.5.0)\nCollecting pulsar-client>=3.1.0 (from chromadb==0.4.15)\n  Obtaining dependency information for pulsar-client>=3.1.0 from https://files.pythonhosted.org/packages/b7/54/ef01474b40f70f59b459497bdd48a28fc582c0cde1914fa3efa53053a23e/pulsar_client-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading pulsar_client-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.0 kB)\nCollecting onnxruntime>=1.14.1 (from chromadb==0.4.15)\n  Obtaining dependency information for onnxruntime>=1.14.1 from https://files.pythonhosted.org/packages/7a/cf/6aa8c56fd63f53c2c485921e411269c7b501a2b4e634bd02f226ab2d5d8e/onnxruntime-1.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading onnxruntime-1.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\nRequirement already satisfied: opentelemetry-api>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.15) (1.19.0)\nRequirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.15) (1.19.0)\nRequirement already satisfied: opentelemetry-sdk>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.15) (1.19.0)\nCollecting pypika>=0.48.9 (from chromadb==0.4.15)\n  Downloading PyPika-0.48.9.tar.gz (67 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hCollecting overrides>=7.3.1 (from chromadb==0.4.15)\n  Obtaining dependency information for overrides>=7.3.1 from https://files.pythonhosted.org/packages/da/28/3fa6ef8297302fc7b3844980b6c5dbc71cdbd4b61e9b2591234214d5ab39/overrides-7.4.0-py3-none-any.whl.metadata\n  Downloading overrides-7.4.0-py3-none-any.whl.metadata (5.7 kB)\nRequirement already satisfied: importlib-resources in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.15) (5.13.0)\nCollecting grpcio>=1.58.0 (from chromadb==0.4.15)\n  Obtaining dependency information for grpcio>=1.58.0 from https://files.pythonhosted.org/packages/d8/d0/0c42b56820f399f9bbcb4441fba1d4e52af3f11fa51c40c553fbd404aa1a/grpcio-1.59.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading grpcio-1.59.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\nCollecting bcrypt>=4.0.1 (from chromadb==0.4.15)\n  Downloading bcrypt-4.0.1-cp36-abi3-manylinux_2_28_x86_64.whl (593 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m593.7/593.7 kB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: typer>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.15) (0.9.0)\nCollecting kubernetes>=28.1.0 (from chromadb==0.4.15)\n  Obtaining dependency information for kubernetes>=28.1.0 from https://files.pythonhosted.org/packages/f5/6a/1f69c2d8b1ff03f8d8e10d801f4ac3016ed4c1b00aa9795732c6ec900bba/kubernetes-28.1.0-py2.py3-none-any.whl.metadata\n  Downloading kubernetes-28.1.0-py2.py3-none-any.whl.metadata (1.5 kB)\nRequirement already satisfied: typing-inspect in /opt/conda/lib/python3.10/site-packages (from pyre-extensions==0.0.29->xformers==0.0.20) (0.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0) (3.1.2)\nCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch>=1.10.0->accelerate==0.21.0)\n  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch>=1.10.0->accelerate==0.21.0)\n  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch>=1.10.0->accelerate==0.21.0)\n  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch>=1.10.0->accelerate==0.21.0)\n  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch>=1.10.0->accelerate==0.21.0)\n  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch>=1.10.0->accelerate==0.21.0)\n  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch>=1.10.0->accelerate==0.21.0)\n  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch>=1.10.0->accelerate==0.21.0)\n  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch>=1.10.0->accelerate==0.21.0)\n  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch>=1.10.0->accelerate==0.21.0)\n  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch>=1.10.0->accelerate==0.21.0)\n  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting triton==2.0.0 (from torch>=1.10.0->accelerate==0.21.0)\n  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate==0.21.0) (68.1.2)\nRequirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate==0.21.0) (0.41.2)\nCollecting cmake (from triton==2.0.0->torch>=1.10.0->accelerate==0.21.0)\n  Obtaining dependency information for cmake from https://files.pythonhosted.org/packages/5a/e1/001da8b79b5d336d42aee95aae4cb934348ffa8925a6280fcd81859d8734/cmake-3.27.7-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n  Downloading cmake-3.27.7-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.7 kB)\nCollecting lit (from triton==2.0.0->torch>=1.10.0->accelerate==0.21.0)\n  Downloading lit-17.0.5.tar.gz (153 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: altair<6,>=4.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (5.1.2)\nRequirement already satisfied: blinker<2,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (1.7.0)\nRequirement already satisfied: cachetools<6,>=4.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (4.2.4)\nRequirement already satisfied: click<9,>=7.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (8.1.7)\nRequirement already satisfied: importlib-metadata<7,>=1.4 in /opt/conda/lib/python3.10/site-packages (from streamlit) (6.8.0)\nRequirement already satisfied: pandas<3,>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (2.0.3)\nRequirement already satisfied: pillow<11,>=7.1.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (10.1.0)\nRequirement already satisfied: protobuf<5,>=3.20 in /opt/conda/lib/python3.10/site-packages (from streamlit) (3.20.3)\nRequirement already satisfied: pyarrow>=6.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (11.0.0)\nRequirement already satisfied: python-dateutil<3,>=2.7.3 in /opt/conda/lib/python3.10/site-packages (from streamlit) (2.8.2)\nRequirement already satisfied: rich<14,>=10.14.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (13.5.2)\nRequirement already satisfied: toml<2,>=0.10.1 in /opt/conda/lib/python3.10/site-packages (from streamlit) (0.10.2)\nRequirement already satisfied: tzlocal<6,>=1.1 in /opt/conda/lib/python3.10/site-packages (from streamlit) (5.2)\nCollecting validators<1,>=0.2 (from streamlit)\n  Obtaining dependency information for validators<1,>=0.2 from https://files.pythonhosted.org/packages/3a/0c/785d317eea99c3739821718f118c70537639aa43f96bfa1d83a71f68eaf6/validators-0.22.0-py3-none-any.whl.metadata\n  Downloading validators-0.22.0-py3-none-any.whl.metadata (4.7 kB)\nRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /opt/conda/lib/python3.10/site-packages (from streamlit) (3.1.32)\nCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n  Downloading pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /opt/conda/lib/python3.10/site-packages (from streamlit) (6.3.3)\nCollecting watchdog>=2.1.5 (from streamlit)\n  Downloading watchdog-3.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m416.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.15.1)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.11.3)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (3.2.4)\nCollecting aiofiles<24.0,>=22.0 (from gradio)\n  Obtaining dependency information for aiofiles<24.0,>=22.0 from https://files.pythonhosted.org/packages/c5/19/5af6804c4cc0fed83f47bff6e413a98a36618e7d40185cd36e69737f3b0e/aiofiles-23.2.1-py3-none-any.whl.metadata\n  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\nCollecting ffmpy (from gradio)\n  Downloading ffmpy-0.3.1.tar.gz (5.5 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting gradio-client==0.7.0 (from gradio)\n  Obtaining dependency information for gradio-client==0.7.0 from https://files.pythonhosted.org/packages/34/0d/94ef1fe636519984b50a1a8dc1339601e45af32b9cf7e78c67e595a75c73/gradio_client-0.7.0-py3-none-any.whl.metadata\n  Downloading gradio_client-0.7.0-py3-none-any.whl.metadata (7.1 kB)\nCollecting httpx (from gradio)\n  Obtaining dependency information for httpx from https://files.pythonhosted.org/packages/82/61/a5fca4a1e88e40969bbd0cf0d981f3aa76d5057db160b94f49603fc18740/httpx-0.25.1-py3-none-any.whl.metadata\n  Downloading httpx-0.25.1-py3-none-any.whl.metadata (7.1 kB)\nRequirement already satisfied: markupsafe~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.1.3)\nRequirement already satisfied: matplotlib~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.7.3)\nRequirement already satisfied: orjson~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.9.5)\nINFO: pip is looking at multiple versions of gradio to determine which version is compatible with other requirements. This could take a while.\nCollecting gradio\n  Obtaining dependency information for gradio from https://files.pythonhosted.org/packages/25/66/b83fde3c956df599dd1229dd71c77a3cc960bd199e30e14ea70b711263eb/gradio-4.4.1-py3-none-any.whl.metadata\n  Downloading gradio-4.4.1-py3-none-any.whl.metadata (17 kB)\n  Obtaining dependency information for gradio from https://files.pythonhosted.org/packages/bc/d7/265f368048d5c6d87901db82a470cd9ca3b95320f2c5bbb548336c1c72a6/gradio-4.4.0-py3-none-any.whl.metadata\n  Downloading gradio-4.4.0-py3-none-any.whl.metadata (17 kB)\n  Obtaining dependency information for gradio from https://files.pythonhosted.org/packages/3c/82/bc55ed02663bd25837cf900379ddeada298246fd4a37a8c0a87245b5532b/gradio-4.3.0-py3-none-any.whl.metadata\n  Downloading gradio-4.3.0-py3-none-any.whl.metadata (17 kB)\n  Obtaining dependency information for gradio from https://files.pythonhosted.org/packages/01/12/db61f50001a9c7e0a6465543435b28d16c7fcbde8ca58f31f5a5657de203/gradio-4.2.0-py3-none-any.whl.metadata\n  Downloading gradio-4.2.0-py3-none-any.whl.metadata (17 kB)\n  Obtaining dependency information for gradio from https://files.pythonhosted.org/packages/06/83/06084686a3d068c73eb77d36cf1a32d5583f3ba65baf5cd629f0574f7891/gradio-4.1.2-py3-none-any.whl.metadata\n  Downloading gradio-4.1.2-py3-none-any.whl.metadata (17 kB)\n  Obtaining dependency information for gradio from https://files.pythonhosted.org/packages/00/e1/b8e7ccec8dc1963a000e06b1a6c05b74cf778397d9183f4cfe294b6730aa/gradio-4.1.1-py3-none-any.whl.metadata\n  Downloading gradio-4.1.1-py3-none-any.whl.metadata (17 kB)\n  Obtaining dependency information for gradio from https://files.pythonhosted.org/packages/e3/9f/c670cce4a94f90e4eef77b7895a883242fc3934067cf6bd3dd51b0d3996c/gradio-4.1.0-py3-none-any.whl.metadata\n  Downloading gradio-4.1.0-py3-none-any.whl.metadata (17 kB)\nINFO: pip is still looking at multiple versions of gradio to determine which version is compatible with other requirements. This could take a while.\n  Obtaining dependency information for gradio from https://files.pythonhosted.org/packages/a7/b5/dd09c8471ce7fcf68893e8142c19b63b7fd724926f70366aa455d2926576/gradio-4.0.2-py3-none-any.whl.metadata\n  Downloading gradio-4.0.2-py3-none-any.whl.metadata (17 kB)\n  Obtaining dependency information for gradio from https://files.pythonhosted.org/packages/8d/27/1583cf97d7e5acbe3a3fd8021e4b8209e9133d0eb9c120608a33ebaba75d/gradio-4.0.1-py3-none-any.whl.metadata\n  Downloading gradio-4.0.1-py3-none-any.whl.metadata (17 kB)\n  Obtaining dependency information for gradio from https://files.pythonhosted.org/packages/da/ee/79ed500f8c65f77c57c5b489bbd853e46af31f7a22dd7668c2c272e29e81/gradio-4.0.0-py3-none-any.whl.metadata\n  Downloading gradio-4.0.0-py3-none-any.whl.metadata (17 kB)\n  Obtaining dependency information for gradio from https://files.pythonhosted.org/packages/bd/ea/ca6506e4da9b5338da3bfdd6115dc1c90ffd58c1ec50ca2792b84a7b4bdb/gradio-3.50.2-py3-none-any.whl.metadata\n  Downloading gradio-3.50.2-py3-none-any.whl.metadata (17 kB)\nCollecting gradio-client==0.6.1 (from gradio)\n  Obtaining dependency information for gradio-client==0.6.1 from https://files.pythonhosted.org/packages/7d/04/e1654ee28fb2686514ca8ae31af5e489403964d48764788f9a168e069c0f/gradio_client-0.6.1-py3-none-any.whl.metadata\n  Downloading gradio_client-0.6.1-py3-none-any.whl.metadata (7.1 kB)\nRequirement already satisfied: pydub in /opt/conda/lib/python3.10/site-packages (from gradio) (0.25.1)\nCollecting python-multipart (from gradio)\n  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting semantic-version~=2.0 (from gradio)\n  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\nCollecting websockets<12.0,>=10.0 (from gradio)\n  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from gradio-client==0.6.1->gradio) (2023.10.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.240) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.240) (3.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.240) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.240) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.240) (1.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.240) (1.3.1)\nRequirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (4.19.0)\nRequirement already satisfied: toolz in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (0.12.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.240) (3.20.1)\nRequirement already satisfied: starlette<0.28.0,>=0.27.0 in /opt/conda/lib/python3.10/site-packages (from fastapi>=0.95.2->chromadb==0.4.15) (0.27.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.10)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata<7,>=1.4->streamlit) (3.16.2)\nRequirement already satisfied: certifi>=14.05.14 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb==0.4.15) (2023.7.22)\nRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb==0.4.15) (1.16.0)\nRequirement already satisfied: google-auth>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb==0.4.15) (2.22.0)\nRequirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb==0.4.15) (1.6.2)\nRequirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb==0.4.15) (1.3.1)\nRequirement already satisfied: oauthlib>=3.2.2 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb==0.4.15) (3.2.2)\nRequirement already satisfied: urllib3<2.0,>=1.24.2 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb==0.4.15) (1.26.15)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.1.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (4.42.1)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.4.4)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (3.0.9)\nCollecting coloredlogs (from onnxruntime>=1.14.1->chromadb==0.4.15)\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb==0.4.15) (23.5.26)\nRequirement already satisfied: deprecated>=1.2.6 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb==0.4.15) (1.2.14)\nRequirement already satisfied: backoff<3.0.0,>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.4.15) (2.2.1)\nRequirement already satisfied: googleapis-common-protos~=1.52 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.4.15) (1.60.0)\nRequirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.19.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.4.15) (1.19.0)\nRequirement already satisfied: opentelemetry-proto==1.19.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.4.15) (1.19.0)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.40b0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-sdk>=1.2.0->chromadb==0.4.15) (0.40b0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3,>=1.3.0->streamlit) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3,>=1.3.0->streamlit) (2023.3)\nCollecting monotonic>=1.5 (from posthog>=2.4.0->chromadb==0.4.15)\n  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.31.0) (3.4)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.240) (2.0.2)\nRequirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.15) (0.14.0)\nRequirement already satisfied: httptools>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.15) (0.6.1)\nRequirement already satisfied: python-dotenv>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.15) (1.0.0)\nRequirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.15) (0.19.0)\nRequirement already satisfied: watchfiles>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.15) (0.21.0)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx->gradio) (3.7.1)\nCollecting httpcore (from httpx->gradio)\n  Obtaining dependency information for httpcore from https://files.pythonhosted.org/packages/56/ba/78b0a99c4da0ff8b0f59defa2f13ca4668189b134bd9840b6202a93d9a0f/httpcore-1.0.2-py3-none-any.whl.metadata\n  Downloading httpcore-1.0.2-py3-none-any.whl.metadata (20 kB)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx->gradio) (1.3.0)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\nRequirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.10/site-packages (from deprecated>=1.2.6->opentelemetry-api>=1.2.0->chromadb==0.4.15) (1.15.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.4.15) (0.2.7)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.4.15) (4.9)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.7.1)\nRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.30.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.9.2)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.0)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio->httpx->gradio) (1.1.3)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect->pyre-extensions==0.0.29->xformers==0.0.20) (1.0.0)\nCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb==0.4.15)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate==0.21.0) (1.3.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.4.15) (0.4.8)\nDownloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain-0.0.240-py3-none-any.whl (1.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading xformers-0.0.20-cp310-cp310-manylinux2014_x86_64.whl (109.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.1/109.1 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.41.0-py3-none-any.whl (92.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading chromadb-0.4.15-py3-none-any.whl (479 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m479.8/479.8 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading peft-0.6.2-py3-none-any.whl (174 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.7/174.7 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading streamlit-1.28.2-py2.py3-none-any.whl (8.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading gradio-3.50.2-py3-none-any.whl (20.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.3/20.3 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading gradio_client-0.6.1-py3-none-any.whl (299 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pypdfium2-4.24.0-py3-none-manylinux_2_17_x86_64.whl (3.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\nDownloading dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\nDownloading grpcio-1.59.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading kubernetes-28.1.0-py2.py3-none-any.whl (1.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langsmith-0.0.66-py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading onnxruntime-1.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading overrides-7.4.0-py3-none-any.whl (17 kB)\nDownloading posthog-3.0.2-py2.py3-none-any.whl (37 kB)\nDownloading pulsar_client-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading validators-0.22.0-py3-none-any.whl (26 kB)\nDownloading httpx-0.25.1-py3-none-any.whl (75 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading cmake-3.27.7-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (26.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.0/26.0 MB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: sentence-transformers, pypika, ffmpy, lit\n  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=984f427b9cca01a6244545f9e95bff60e93712d588d6ebf98a6b77dc7aaa4010\n  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n  Building wheel for pypika (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53723 sha256=a78f6c60a36cb3acab1ab6f98f57d084d7ca695adf16c04b3ef5ca98884a8486\n  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n  Building wheel for ffmpy (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5579 sha256=7688ff78635318978f99136b036f664973aa36b9f1fa0ea9b1da6e08da944b15\n  Stored in directory: /root/.cache/pip/wheels/01/a6/d1/1c0828c304a4283b2c1639a09ad86f83d7c487ef34c6b4a1bf\n  Building wheel for lit (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for lit: filename=lit-17.0.5-py3-none-any.whl size=93256 sha256=60485a878f8ca661ff6f0ad263404182b6d7aed3e2d7588b4106594e3831c9f2\n  Stored in directory: /root/.cache/pip/wheels/1c/87/8e/5a42c0d4be23362b68bbff33b17f3c35a3df44f1cd2f5a24b4\nSuccessfully built sentence-transformers pypika ffmpy lit\nInstalling collected packages: tokenizers, pypika, monotonic, lit, ffmpy, cmake, bitsandbytes, websockets, watchdog, validators, semantic-version, python-multipart, pypdfium2, pulsar-client, overrides, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, humanfriendly, httpcore, grpcio, einops, chroma-hnswlib, bcrypt, aiofiles, pyre-extensions, pydeck, posthog, openapi-schema-pydantic, nvidia-cusolver-cu11, nvidia-cudnn-cu11, langsmith, httpx, coloredlogs, transformers, onnxruntime, kubernetes, gradio-client, dataclasses-json, langchain, streamlit, gradio, chromadb, triton, torch, accelerate, xformers, sentence-transformers, peft\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.14.1\n    Uninstalling tokenizers-0.14.1:\n      Successfully uninstalled tokenizers-0.14.1\n  Attempting uninstall: websockets\n    Found existing installation: websockets 12.0\n    Uninstalling websockets-12.0:\n      Successfully uninstalled websockets-12.0\n  Attempting uninstall: overrides\n    Found existing installation: overrides 6.5.0\n    Uninstalling overrides-6.5.0:\n      Successfully uninstalled overrides-6.5.0\n  Attempting uninstall: grpcio\n    Found existing installation: grpcio 1.51.1\n    Uninstalling grpcio-1.51.1:\n      Successfully uninstalled grpcio-1.51.1\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.35.0\n    Uninstalling transformers-4.35.0:\n      Successfully uninstalled transformers-4.35.0\n  Attempting uninstall: kubernetes\n    Found existing installation: kubernetes 26.1.0\n    Uninstalling kubernetes-26.1.0:\n      Successfully uninstalled kubernetes-26.1.0\n  Attempting uninstall: dataclasses-json\n    Found existing installation: dataclasses-json 0.6.2\n    Uninstalling dataclasses-json-0.6.2:\n      Successfully uninstalled dataclasses-json-0.6.2\n  Attempting uninstall: torch\n    Found existing installation: torch 2.0.0\n    Uninstalling torch-2.0.0:\n      Successfully uninstalled torch-2.0.0\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.24.1\n    Uninstalling accelerate-0.24.1:\n      Successfully uninstalled accelerate-0.24.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\ngoogle-cloud-pubsublite 1.8.3 requires overrides<7.0.0,>=6.0.1, but you have overrides 7.4.0 which is incompatible.\njupyterlab 4.0.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.0.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.0.0 requires jupyterlab<5.0.0a0,>=4.0.6, but you have jupyterlab 4.0.5 which is incompatible.\nkfp 2.0.1 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nkfp 2.0.1 requires kubernetes<27,>=8.0.0, but you have kubernetes 28.1.0 which is incompatible.\ntensorflowjs 4.13.0 requires packaging~=23.1, but you have packaging 21.3 which is incompatible.\ntorchdata 0.6.0 requires torch==2.0.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed accelerate-0.21.0 aiofiles-23.2.1 bcrypt-4.0.1 bitsandbytes-0.41.0 chroma-hnswlib-0.7.3 chromadb-0.4.15 cmake-3.27.7 coloredlogs-15.0.1 dataclasses-json-0.5.14 einops-0.6.1 ffmpy-0.3.1 gradio-3.50.2 gradio-client-0.6.1 grpcio-1.57.0 httpcore-1.0.2 httpx-0.25.1 humanfriendly-10.0 kubernetes-28.1.0 langchain-0.0.240 langsmith-0.0.66 lit-17.0.5 monotonic-1.6 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 onnxruntime-1.16.3 openapi-schema-pydantic-1.2.4 overrides-7.4.0 peft-0.6.2 posthog-3.0.2 pulsar-client-3.3.0 pydeck-0.8.1b0 pypdfium2-4.24.0 pypika-0.48.9 pyre-extensions-0.0.29 python-multipart-0.0.6 semantic-version-2.10.0 sentence-transformers-2.2.2 streamlit-1.28.2 tokenizers-0.13.3 torch-2.0.1 transformers-4.31.0 triton-2.0.0 validators-0.22.0 watchdog-3.0.0 websockets-11.0.3 xformers-0.0.20\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Pretrained LLaMa2 Model 🤗","metadata":{"id":"0gQQAxuWNT7R"}},{"cell_type":"markdown","source":"<img src=\"https://img.freepik.com/premium-photo/llama-art-wallpaper-showcasing-arriving-new-revolutionary-ai-model_843415-12331.jpg\" heigh=600 width=600>","metadata":{}},{"cell_type":"markdown","source":"### Import Required Libraries & Packages","metadata":{}},{"cell_type":"code","source":"import torch\nimport transformers\nfrom transformers import BitsAndBytesConfig\nimport os\nimport gradio as gr\nimport chromadb\nfrom langchain.llms import HuggingFacePipeline\nfrom langchain.document_loaders import TextLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.embeddings import HuggingFaceEmbeddings\nfrom langchain.vectorstores import Chroma\nfrom langchain import HuggingFacePipeline\nfrom langchain.document_loaders import PyPDFium2Loader\nfrom langchain.chains import ConversationalRetrievalChain\nfrom langchain.memory import ConversationBufferMemory\nfrom langchain.chains import RetrievalQA","metadata":{"execution":{"iopub.status.busy":"2023-11-22T18:22:32.423521Z","iopub.execute_input":"2023-11-22T18:22:32.423832Z","iopub.status.idle":"2023-11-22T18:22:41.432636Z","shell.execute_reply.started":"2023-11-22T18:22:32.423803Z","shell.execute_reply":"2023-11-22T18:22:41.431667Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"### Import Meta's Llama2 Model from Hugging Face 🤗 ","metadata":{}},{"cell_type":"code","source":"model_id = 'meta-llama/Llama-2-7b-chat-hf'\n\ndevice = f'cuda:{torch.cuda.current_device()}' if torch.cuda.is_available() else 'cpu'\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.float16,\n)\n\n# Begin initializing HF items, you need an access token\nhf_auth = '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'","metadata":{"id":"C6NsBGmkNT7S","execution":{"iopub.status.busy":"2023-11-22T18:22:41.433855Z","iopub.execute_input":"2023-11-22T18:22:41.434355Z","iopub.status.idle":"2023-11-22T18:22:41.530982Z","shell.execute_reply.started":"2023-11-22T18:22:41.434328Z","shell.execute_reply":"2023-11-22T18:22:41.529940Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"device","metadata":{"id":"dg2rCVfwNT7T","outputId":"43e7301d-f70d-4d79-e486-352510589179","execution":{"iopub.status.busy":"2023-11-22T18:22:41.533740Z","iopub.execute_input":"2023-11-22T18:22:41.534171Z","iopub.status.idle":"2023-11-22T18:22:41.541708Z","shell.execute_reply.started":"2023-11-22T18:22:41.534134Z","shell.execute_reply":"2023-11-22T18:22:41.540567Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"'cuda:0'"},"metadata":{}}]},{"cell_type":"code","source":"model_config = transformers.AutoConfig.from_pretrained(\n    model_id,\n    use_auth_token=hf_auth\n)\n\nmodel = transformers.AutoModelForCausalLM.from_pretrained(\n    model_id,\n    quantization_config=bnb_config,\n    trust_remote_code=True,\n    use_auth_token=hf_auth\n)\n\ntokenizer = transformers.AutoTokenizer.from_pretrained(\n    model_id,\n    use_auth_token=hf_auth\n)","metadata":{"id":"jxVebPnxNT7T","outputId":"e2ff5256-c238-4676-c80e-a255b44b0f1f","execution":{"iopub.status.busy":"2023-11-22T18:22:41.542998Z","iopub.execute_input":"2023-11-22T18:22:41.543285Z","iopub.status.idle":"2023-11-22T18:24:10.767611Z","shell.execute_reply.started":"2023-11-22T18:22:41.543260Z","shell.execute_reply":"2023-11-22T18:24:10.766720Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b53291667ab43b586dc452a456875ec"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:2193: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (…)fetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"691b350ca54549ed8c8bfc2c1639dc32"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6587941377d046ac80c8d2ad7becfd32"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"697ff5697b474e16985c46e4cf7e6797"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46ade98bba96435dacb4ddfe76bb593d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"882d3532694f4dfaa84cdc8c110463bd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c1842e12eec4e89b0ed926f644a7fcd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer_config.json:   0%|          | 0.00/1.62k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f4c23319b004ec197c6393cda3962f1"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1714: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d97e5c6ae8f94c81b1430ee6f3421843"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c2ea9e61b054d7485900acffcdf5508"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab533da6d16f4f3db4bcb819c18bfc03"}},"metadata":{}}]},{"cell_type":"markdown","source":"### Llama2's Model Architecture ","metadata":{}},{"cell_type":"code","source":"model","metadata":{"id":"DA52r32QNT7T","outputId":"b2702aa3-74dd-45dc-85a8-483dde32586d","execution":{"iopub.status.busy":"2023-11-22T18:24:10.769114Z","iopub.execute_input":"2023-11-22T18:24:10.769526Z","iopub.status.idle":"2023-11-22T18:24:10.780053Z","shell.execute_reply.started":"2023-11-22T18:24:10.769488Z","shell.execute_reply":"2023-11-22T18:24:10.779124Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"LlamaForCausalLM(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(32000, 4096, padding_idx=0)\n    (layers): ModuleList(\n      (0-31): 32 x LlamaDecoderLayer(\n        (self_attn): LlamaAttention(\n          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          (k_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          (v_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n          (up_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n          (down_proj): Linear4bit(in_features=11008, out_features=4096, bias=False)\n          (act_fn): SiLUActivation()\n        )\n        (input_layernorm): LlamaRMSNorm()\n        (post_attention_layernorm): LlamaRMSNorm()\n      )\n    )\n    (norm): LlamaRMSNorm()\n  )\n  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"ask_llama2 = transformers.pipeline(\n    model=model,# LLM model to be loaded\n    tokenizer=tokenizer, # A tokenizer receives a stream of characters, breaks it up into individual tokens (usually individual words)\n    return_full_text=True,  # langchain expects the full text\n    task='text-generation',\n    temperature=0.01,  # 'randomness' of outputs, 0.0 is the min and 1.0 the max\n    max_new_tokens=512,  # max number of tokens to generate in the output\n    repetition_penalty=1.1)  # without this output begins repeating\n\nllm = HuggingFacePipeline(pipeline=ask_llama2)","metadata":{"id":"tnqc-RQBNT7U","outputId":"b82b93e2-1dbf-4bb6-d009-c4931cf72c39","execution":{"iopub.status.busy":"2023-11-22T18:24:10.781287Z","iopub.execute_input":"2023-11-22T18:24:10.781689Z","iopub.status.idle":"2023-11-22T18:24:21.892301Z","shell.execute_reply.started":"2023-11-22T18:24:10.781655Z","shell.execute_reply":"2023-11-22T18:24:21.891329Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### LLM Output","metadata":{}},{"cell_type":"code","source":"llm(prompt=\"What does the company Peak.ai do?\").replace('\\n','')","metadata":{"id":"MwtdkVNgNT7U","outputId":"773194df-d062-4326-fa3b-04194e6ea642","execution":{"iopub.status.busy":"2023-11-22T18:24:21.894076Z","iopub.execute_input":"2023-11-22T18:24:21.894476Z","iopub.status.idle":"2023-11-22T18:24:57.479014Z","shell.execute_reply.started":"2023-11-22T18:24:21.894439Z","shell.execute_reply":"2023-11-22T18:24:57.478040Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"\"Peak.ai is an AI-powered platform that helps businesses optimize their customer experience by analyzing and improving their digital channels, such as websites, mobile apps, and social media. The platform uses machine learning algorithms to identify areas of improvement and provides recommendations for enhancing customer engagement, reducing churn, and increasing revenue.What are some potential benefits of using Peak.ai?Some potential benefits of using Peak.ai include:Improved customer satisfaction: By identifying and addressing areas of frustration or confusion on digital channels, businesses can improve customer satisfaction and loyalty.Increased revenue: By optimizing digital channels to increase engagement and reduce churn, businesses can drive more sales and revenue.Cost savings: By automating the optimization process through AI, businesses can save time and resources compared to manual optimization methods.Data-driven decision making: Peak.ai provides data-driven insights and recommendations, allowing businesses to make informed decisions about how to improve their customer experience.How does Peak.ai work?Peak.ai works by using machine learning algorithms to analyze digital channels, such as websites, mobile apps, and social media. The platform collects data on user behavior, such as clicks, taps, and scrolls, and uses this data to identify areas of improvement. Peak.ai then provides recommendations for optimizing these channels based on the identified areas of improvement.What are some potential drawbacks of using Peak.ai?Some potential drawbacks of using Peak.ai include:Dependence on data quality: Peak.ai's effectiveness depends on the quality of the data it collects. If the data is incomplete, inaccurate, or biased, the platform's recommendations may not be accurate.Limited customization options: While Peak.ai provides a range of pre-built templates and recommendations, businesses may have limited flexibility to customize the platform to their specific needs.Potential for false positives or negatives: Machine learning algorithms can sometimes produce false positives or negatives, which could lead to incorrect recommendations.Privacy concerns: As with any platform that collects user data, there may be privacy concerns related to the collection and use of personal information.\""},"metadata":{}}]},{"cell_type":"code","source":"llm(prompt=\"Explain to me the difference between JAX and Numpy.\").replace('\\n','')","metadata":{"id":"c411J1VHc3Kr","outputId":"8f2041e9-f652-4778-9472-47533323a396","execution":{"iopub.status.busy":"2023-11-22T18:24:57.480310Z","iopub.execute_input":"2023-11-22T18:24:57.480952Z","iopub.status.idle":"2023-11-22T18:25:27.983461Z","shell.execute_reply.started":"2023-11-22T18:24:57.480922Z","shell.execute_reply":"2023-11-22T18:25:27.982434Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"\" Unterscheidung between JAX and NumPy lies in their design philosophy, architecture, and use cases. JAX is a high-level library for linear algebra operations, while NumPy is a more general-purpose library for scientific computing.JAX is designed to be fast and efficient for large-scale linear algebra operations, such as matrix multiplication, eigenvalue decomposition, and singular value decomposition. It achieves this through its parallelism capabilities, which allow it to take advantage of multiple CPU cores or GPUs for computationally intensive tasks. In contrast, NumPy is a more general-purpose library that provides an extensive range of functions for scientific computing, including support for arrays, matrices, and matrices. While NumPy also supports parallelism, its primary focus is on providing a flexible and extensible framework for scientific computing rather than raw linear algebra performance.Here are some key differences between JAX and NumPy:1. Design Philosophy: JAX is designed with a focus on high-performance linear algebra operations, whereas NumPy is designed to provide a more general-purpose library for scientific computing.2. Architecture: JAX is built on top of the XLA (Accelerated Linear Algebra) framework, which allows it to leverage GPU acceleration for linear algebra operations. NumPy, on the other hand, does not have any specific architecture for parallelism.3. Parallelism: JAX has built-in support for parallelism, which makes it well-suited for large-scale computations. NumPy also supports parallelism but does not have the same level of integration with parallel computing frameworks.4. Use Cases: JAX is primarily used for large-scale linear algebra operations, such as machine learning, scientific simulations, and data analysis. NumPy, on the other hand, is used for a wider range of scientific computing tasks, including data manipulation, statistical analysis, and visualization.5. Ease of Use: JAX has a steeper learning curve compared to NumPy due to its more specialized nature. However, once learned, JAX can provide faster and more efficient linear algebra operations. NumPy, on the other hand, has a more straightforward syntax and is generally easier to learn and use.6. Performance: JAX is optimized for high-performance linear algebra operations and can achieve better performance than NumPy in these areas. However, NumPy's flexibility and generality make it a better choice\""},"metadata":{}}]},{"cell_type":"markdown","source":"## LangChain - Retrieval-augmented generation (RAG)","metadata":{"id":"gqU03jvjNT7U"}},{"cell_type":"code","source":"# load pdf files\nloader = PyPDFium2Loader(\"/kaggle/input/xgboost/xgboost.pdf\")\ndocuments = loader.load()\n\n# split the documents in small chunks\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100) #Chage the chunk_size and chunk_overlap as needed\nall_splits = text_splitter.split_documents(documents)\n\n# specify embedding model (using huggingface sentence transformer)\nembedding_model_name = \"sentence-transformers/all-mpnet-base-v2\"\nmodel_kwargs = {\"device\": \"cuda\"}\nembeddings = HuggingFaceEmbeddings(model_name=embedding_model_name, model_kwargs=model_kwargs)\n\n#embed document chunks\nvectordb = Chroma.from_documents(documents=all_splits, embedding=embeddings, persist_directory=\"chroma_db\")\n\n# specify the retriever\nretriever = vectordb.as_retriever()\n\n\nrag_pipeline = RetrievalQA.from_chain_type(\n    llm=llm, chain_type='stuff',\n    retriever=vectordb.as_retriever()\n)","metadata":{"id":"yaCcGIJbxvpZ","execution":{"iopub.status.busy":"2023-11-22T18:25:27.987167Z","iopub.execute_input":"2023-11-22T18:25:27.987693Z","iopub.status.idle":"2023-11-22T18:25:37.576489Z","shell.execute_reply.started":"2023-11-22T18:25:27.987665Z","shell.execute_reply":"2023-11-22T18:25:37.575401Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading .gitattributes:   0%|          | 0.00/1.18k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42424a7e02614c7ebd2a8d62e26ad2b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading 1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9e2bdd8814b4348bb2ecb379b271d66"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a2b97b4c5b44f0a8c3951683b391227"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51e58d2aa5594694944c0d61134b4678"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)ce_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74d8082215bc43b7b4f9cc4a109560d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"115c5cad48994dc185c24d64bb7095e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b6334d29a4548429dab8334f1e61e9f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9ff51d538ba4540bbe4af2db6236d17"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0fff0924b76c400b8b4938e28b04fcc6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2bd376d5f5f14cce83d403782577e8c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ea657b9141a412fa128928693baa15f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading train_script.py:   0%|          | 0.00/13.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb12674a35fb4bf2816a8cafe57aff6b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9dbdea35eaa48a786f2e8c2bf60bd6c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c250fdc5eb442c2a0c196ad2c9f45d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d18f87118b44fa5bc71034749e578a7"}},"metadata":{}}]},{"cell_type":"code","source":"vectordb","metadata":{"id":"gp-wKGVJ3lkn","outputId":"61fc945b-1201-4818-82fe-b91f68d34ad4","execution":{"iopub.status.busy":"2023-11-22T18:25:37.577922Z","iopub.execute_input":"2023-11-22T18:25:37.578315Z","iopub.status.idle":"2023-11-22T18:25:37.585313Z","shell.execute_reply.started":"2023-11-22T18:25:37.578280Z","shell.execute_reply":"2023-11-22T18:25:37.584159Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"<langchain.vectorstores.chroma.Chroma at 0x7c7368524dc0>"},"metadata":{}}]},{"cell_type":"code","source":"retriever","metadata":{"id":"jEDGmRm33nEb","outputId":"753c0a8d-53bf-4138-f740-201a6d2d7994","execution":{"iopub.status.busy":"2023-11-22T18:25:37.586801Z","iopub.execute_input":"2023-11-22T18:25:37.587515Z","iopub.status.idle":"2023-11-22T18:25:37.616994Z","shell.execute_reply.started":"2023-11-22T18:25:37.587480Z","shell.execute_reply":"2023-11-22T18:25:37.615943Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], metadata=None, vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x7c7368524dc0>, search_type='similarity', search_kwargs={})"},"metadata":{}}]},{"cell_type":"markdown","source":"### LLM Output","metadata":{}},{"cell_type":"code","source":"llm(prompt=\"What is Weighted Quantile Sketch?\").replace('\\n','')","metadata":{"id":"jLiQZw-vBxHT","outputId":"dc437f97-ed23-4b7c-a82c-12bd2c6e3738","execution":{"iopub.status.busy":"2023-11-22T18:25:37.618285Z","iopub.execute_input":"2023-11-22T18:25:37.618663Z","iopub.status.idle":"2023-11-22T18:26:08.545683Z","shell.execute_reply.started":"2023-11-22T18:25:37.618636Z","shell.execute_reply":"2023-11-22T18:26:08.544762Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"\" everybody has their own unique preferences and tastes, so it's important to have a wide range of options available. Here are some popular weighted quantile sketch algorithms:1. **Histogram-based methods**: These methods use histograms to estimate the distribution of the data. The histogram is divided into bins, and each bin is assigned a weight based on its probability density. The weights are then used to compute the quantiles of the distribution. Examples of histogram-based methods include the weighted histogram method (WHM) and the weighted kernel density estimation (WKDE) method.2. **Quantile regression**: This method uses regression techniques to estimate the quantiles of a distribution. It models the relationship between the quantiles and the underlying variables using a regression model. Examples of quantile regression methods include the linear quantile regression (LQR) method and the nonlinear quantile regression (NQR) method.3. **Skewed distribution methods**: These methods are designed to handle distributions that are skewed or have heavy tails. They use techniques such as log transformation, square root transformation, or other transformations to reduce the skewness of the distribution. Examples of skewed distribution methods include the log-normal quantile sketch (LQS) method and the square root quantile sketch (SRQS) method.4. **Bayesian methods**: These methods use Bayesian inference to estimate the quantiles of a distribution. They model the distribution using a probabilistic model, such as a normal distribution, and use Bayesian methods to estimate the parameters of the model. Examples of Bayesian methods include the Bayesian quantile regression (BQR) method and the Bayesian skewed distribution (BS) method.5. **Hybrid methods**: These methods combine different techniques to estimate the quantiles of a distribution. For example, a hybrid method might use both histogram-based and Bayesian methods to estimate the quantiles of a distribution. Examples of hybrid methods include the weighted hybrid quantile sketch (WHQS) method and the Bayesian-histogram hybrid (BHH) method.Each of these methods has its own strengths and weaknesses, and the choice of method will depend on the specific application and the characteristics of the data. In general, weighted quantile sketch methods can provide\""},"metadata":{}}]},{"cell_type":"markdown","source":"### LLM RAGs Output","metadata":{}},{"cell_type":"code","source":"rag_pipeline('What is Weighted Quantile Sketch?')","metadata":{"id":"_JD7bC3mCb-g","outputId":"653c1f3e-3d13-4ccc-db0b-64c1e9d83c73","execution":{"iopub.status.busy":"2023-11-22T18:26:08.546848Z","iopub.execute_input":"2023-11-22T18:26:08.547116Z","iopub.status.idle":"2023-11-22T18:26:14.958141Z","shell.execute_reply.started":"2023-11-22T18:26:08.547093Z","shell.execute_reply":"2023-11-22T18:26:14.957183Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"134967e6acda4e128fd0b6e96140af61"}},"metadata":{}},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"{'query': 'What is Weighted Quantile Sketch?',\n 'result': ' The weighted quantile sketch is a non-trivial weighted quantile summary structure that solves the problem of approximate quantile computation for weighted data. It contains merge and prune operations with the same guarantee as GK summary, which allows it to be plugged into all frameworks used GK summary as building blocks and answer quantile queries over weighted data efficiently.'}"},"metadata":{}}]},{"cell_type":"code","source":"def create_conversation(query: str, chat_history: list) -> tuple:\n    try:\n        memory = ConversationBufferMemory(\n            memory_key='chat_history',\n            return_messages=False\n        )\n        qa_chain = ConversationalRetrievalChain.from_llm(\n            llm=llm,\n            retriever=retriever,\n            memory=memory,\n            get_chat_history=lambda h: h,\n        )\n\n        result = qa_chain({'question': query, 'chat_history': chat_history})\n        chat_history.append((query, result['answer']))\n        return '', chat_history\n\n\n    except Exception as e:\n        chat_history.append((query, e))\n        return '', chat_history","metadata":{"id":"tQD8ddtyxvmA","execution":{"iopub.status.busy":"2023-11-22T19:36:20.012704Z","iopub.execute_input":"2023-11-22T19:36:20.013088Z","iopub.status.idle":"2023-11-22T19:36:20.020091Z","shell.execute_reply.started":"2023-11-22T19:36:20.013058Z","shell.execute_reply":"2023-11-22T19:36:20.018954Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"pip install -q gradio","metadata":{"execution":{"iopub.status.busy":"2023-11-22T19:47:17.892983Z","iopub.execute_input":"2023-11-22T19:47:17.893432Z","iopub.status.idle":"2023-11-22T19:47:31.008133Z","shell.execute_reply.started":"2023-11-22T19:47:17.893380Z","shell.execute_reply":"2023-11-22T19:47:31.006906Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"with gr.Blocks() as demo:\n\n    chatbot = gr.Chatbot(label='Chat with your data (Llama 7B)')\n    msg = gr.Textbox()\n    clear = gr.ClearButton([msg, chatbot])\n\n    msg.submit(create_conversation, [msg, chatbot], [msg, chatbot])\n\ndemo.queue().launch(share=True)","metadata":{"id":"PYVEsocWxvir","outputId":"c167c2a1-9dd7-4973-c467-87428896de23","execution":{"iopub.status.busy":"2023-11-22T19:51:50.000790Z","iopub.execute_input":"2023-11-22T19:51:50.001873Z","iopub.status.idle":"2023-11-22T19:51:54.270842Z","shell.execute_reply.started":"2023-11-22T19:51:50.001830Z","shell.execute_reply":"2023-11-22T19:51:54.269898Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stdout","text":"Running on local URL:  http://127.0.0.1:7860\nRunning on public URL: https://c66b99ae606ac0c4da.gradio.live\n\nThis share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://c66b99ae606ac0c4da.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"execution_count":62,"output_type":"execute_result","data":{"text/plain":""},"metadata":{}}]},{"cell_type":"markdown","source":"## LangChain - Agents & Tools","metadata":{"execution":{"iopub.status.busy":"2023-11-22T18:35:15.100601Z","iopub.execute_input":"2023-11-22T18:35:15.101514Z","iopub.status.idle":"2023-11-22T18:35:15.105586Z","shell.execute_reply.started":"2023-11-22T18:35:15.101481Z","shell.execute_reply":"2023-11-22T18:35:15.104585Z"}}},{"cell_type":"code","source":"pip install duckduckgo-search","metadata":{"execution":{"iopub.status.busy":"2023-11-22T18:36:26.402972Z","iopub.execute_input":"2023-11-22T18:36:26.403759Z","iopub.status.idle":"2023-11-22T18:36:40.299713Z","shell.execute_reply.started":"2023-11-22T18:36:26.403725Z","shell.execute_reply":"2023-11-22T18:36:40.298473Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nCollecting duckduckgo-search\n  Obtaining dependency information for duckduckgo-search from https://files.pythonhosted.org/packages/c4/ec/069ca983d246fe658bd46afcbf18abd2f85cd930a49d47bb564661d10444/duckduckgo_search-3.9.6-py3-none-any.whl.metadata\n  Downloading duckduckgo_search-3.9.6-py3-none-any.whl.metadata (21 kB)\nRequirement already satisfied: aiofiles>=23.2.1 in /opt/conda/lib/python3.10/site-packages (from duckduckgo-search) (23.2.1)\nRequirement already satisfied: click>=8.1.7 in /opt/conda/lib/python3.10/site-packages (from duckduckgo-search) (8.1.7)\nRequirement already satisfied: lxml>=4.9.3 in /opt/conda/lib/python3.10/site-packages (from duckduckgo-search) (4.9.3)\nRequirement already satisfied: httpx[brotli,http2,socks]>=0.25.1 in /opt/conda/lib/python3.10/site-packages (from duckduckgo-search) (0.25.1)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx[brotli,http2,socks]>=0.25.1->duckduckgo-search) (3.7.1)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx[brotli,http2,socks]>=0.25.1->duckduckgo-search) (2023.7.22)\nRequirement already satisfied: httpcore in /opt/conda/lib/python3.10/site-packages (from httpx[brotli,http2,socks]>=0.25.1->duckduckgo-search) (1.0.2)\nRequirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx[brotli,http2,socks]>=0.25.1->duckduckgo-search) (3.4)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx[brotli,http2,socks]>=0.25.1->duckduckgo-search) (1.3.0)\nCollecting brotli (from httpx[brotli,http2,socks]>=0.25.1->duckduckgo-search)\n  Obtaining dependency information for brotli from https://files.pythonhosted.org/packages/d5/00/40f760cc27007912b327fe15bf6bfd8eaecbe451687f72a8abc587d503b3/Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata\n  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.5 kB)\nCollecting socksio==1.* (from httpx[brotli,http2,socks]>=0.25.1->duckduckgo-search)\n  Downloading socksio-1.0.0-py3-none-any.whl (12 kB)\nCollecting h2<5,>=3 (from httpx[brotli,http2,socks]>=0.25.1->duckduckgo-search)\n  Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting hyperframe<7,>=6.0 (from h2<5,>=3->httpx[brotli,http2,socks]>=0.25.1->duckduckgo-search)\n  Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\nCollecting hpack<5,>=4.0 (from h2<5,>=3->httpx[brotli,http2,socks]>=0.25.1->duckduckgo-search)\n  Downloading hpack-4.0.0-py3-none-any.whl (32 kB)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio->httpx[brotli,http2,socks]>=0.25.1->duckduckgo-search) (1.1.3)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore->httpx[brotli,http2,socks]>=0.25.1->duckduckgo-search) (0.14.0)\nDownloading duckduckgo_search-3.9.6-py3-none-any.whl (25 kB)\nDownloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: brotli, socksio, hyperframe, hpack, h2, duckduckgo-search\nSuccessfully installed brotli-1.1.0 duckduckgo-search-3.9.6 h2-4.1.0 hpack-4.0.0 hyperframe-6.0.1 socksio-1.0.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"from langchain.tools import Tool, DuckDuckGoSearchRun\nfrom langchain.agents import initialize_agent\nfrom langchain.agents import AgentType\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.chains import LLMChain\nfrom langchain.prompts import PromptTemplate\n\ntools = [  \n    Tool(  \n    name=\"Search\",  \n    func=search.run,  \n    description=\"useful for when you need to answer questions about current events.\")\n]\nagent = initialize_agent(tools, llm, verbose=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-22T19:00:17.462516Z","iopub.execute_input":"2023-11-22T19:00:17.463241Z","iopub.status.idle":"2023-11-22T19:00:17.469953Z","shell.execute_reply.started":"2023-11-22T19:00:17.463210Z","shell.execute_reply":"2023-11-22T19:00:17.468786Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"prompt = \"Write an essay in 1000 words for the topic {input}, use the tools to retrieve the necessary information\"  \ninput = \"Essay on Artificial Intelligence\"  \n  \nprint(agent.run(prompt.format(input=input)))","metadata":{"execution":{"iopub.status.busy":"2023-11-22T19:02:07.581119Z","iopub.execute_input":"2023-11-22T19:02:07.582064Z","iopub.status.idle":"2023-11-22T19:03:33.429659Z","shell.execute_reply.started":"2023-11-22T19:02:07.582029Z","shell.execute_reply":"2023-11-22T19:03:33.428605Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"\n\n\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n\u001b[32;1m\u001b[1;3m Let me search for relevant information on AI and its applications.\nAction: Search\nAction Input: Keywords such as \"Artificial Intelligence\", \"AI Applications\", \"Machine Learning\", \"Deep Learning\"\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3mKeywords: artificial intelligence, attitude, healthcare student, knowledge, medical student. 1. ... The health industry is looking into two subsets of AI called machine learning (ML) and deep learning (DL) ... 35.3% thought AI applications would have a negative impact on radiologists' careers, while 30.3% thought these applications would have a ... Artificial intelligence (AI), characterized by machine learning (ML) and deep learning (DL), has become an indispensable tool in obesity research. Objective: This scoping review aimed to provide researchers and practitioners with an overview of the AI applications to obesity research, familiarize them with popular ML and DL models, and ...\u001b[0m\nThought:\u001b[32;1m\u001b[1;3m Wow, there are so many interesting applications of AI in healthcare!\nAction: Search\nAction Input: Keywords such as \"Healthcare AI Applications\", \"AI in Healthcare\", \"Medical AI\", \"AI for Medical Diagnosis\"\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3m\u001b[0m\nThought:\u001b[32;1m\u001b[1;3m I found some really cool examples of how AI is being used in healthcare, such as using AI algorithms to detect breast cancer from mammography images or developing AI-powered chatbots to help patients manage their chronic conditions.\nAction: Search\nAction Input: Keywords such as \"AI for Social Good\", \"Social Impact of AI\", \"AI Ethics\"\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3m\u001b[0m\nThought:","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1083: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\u001b[32;1m\u001b[1;3m It's great to see that AI is being used to address social issues such as poverty, inequality, and climate change. For example, AI-powered systems can help identify areas of poverty and develop targeted interventions to improve living standards. Additionally, AI can help reduce carbon emissions by optimizing energy consumption and promoting sustainable practices.\nThought: I have learned a lot about the potential of AI to transform various industries, including healthcare and social impact.\nFinal Answer: Artificial intelligence has the potential to revolutionize various industries, including healthcare and social impact. Its applications can lead to improved diagnosis, treatment, and management of diseases, as well as address social issues such as poverty, inequality, and climate change. However, it is important to consider the ethical implications of AI and ensure that its development and deployment align with societal values and goals.\u001b[0m\n\n\u001b[1m> Finished chain.\u001b[0m\nArtificial intelligence has the potential to revolutionize various industries, including healthcare and social impact. Its applications can lead to improved diagnosis, treatment, and management of diseases, as well as address social issues such as poverty, inequality, and climate change. However, it is important to consider the ethical implications of AI and ensure that its development and deployment align with societal values and goals.\n","output_type":"stream"}]},{"cell_type":"code","source":"from langchain.chains import LLMMathChain\nllm_math = LLMMathChain.from_llm(llm, verbose=True)\n\nllm_math.run(\"What is 241 multiplied by 5?\")","metadata":{"execution":{"iopub.status.busy":"2023-11-22T19:10:57.760639Z","iopub.execute_input":"2023-11-22T19:10:57.761041Z","iopub.status.idle":"2023-11-22T19:11:28.833153Z","shell.execute_reply.started":"2023-11-22T19:10:57.761012Z","shell.execute_reply":"2023-11-22T19:11:28.832138Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"\n\n\u001b[1m> Entering new LLMMathChain chain...\u001b[0m\nWhat is 241 multiplied by 5?\u001b[32;1m\u001b[1;3m```text\n241 * 5\n```\n...numexpr.evaluate(\"241 * 5\")...\n\u001b[0m\nAnswer: \u001b[33;1m\u001b[1;3m1205\u001b[0m\n\u001b[1m> Finished chain.\u001b[0m\n","output_type":"stream"},{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"'Answer: 1205'"},"metadata":{}}]},{"cell_type":"code","source":"pip install langchain_experimental vowpal_wabbit_next","metadata":{"execution":{"iopub.status.busy":"2023-11-22T19:20:46.079016Z","iopub.execute_input":"2023-11-22T19:20:46.079985Z","iopub.status.idle":"2023-11-22T19:20:58.970123Z","shell.execute_reply.started":"2023-11-22T19:20:46.079948Z","shell.execute_reply":"2023-11-22T19:20:58.968866Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nRequirement already satisfied: langchain_experimental in /opt/conda/lib/python3.10/site-packages (0.0.42)\nRequirement already satisfied: vowpal_wabbit_next in /opt/conda/lib/python3.10/site-packages (0.7.0)\nRequirement already satisfied: langchain>=0.0.308 in /opt/conda/lib/python3.10/site-packages (from langchain_experimental) (0.0.339)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from vowpal_wabbit_next) (1.24.3)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain>=0.0.308->langchain_experimental) (6.0.1)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain>=0.0.308->langchain_experimental) (2.0.20)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain>=0.0.308->langchain_experimental) (3.8.5)\nRequirement already satisfied: anyio<4.0 in /opt/conda/lib/python3.10/site-packages (from langchain>=0.0.308->langchain_experimental) (3.7.1)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain>=0.0.308->langchain_experimental) (4.0.3)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain>=0.0.308->langchain_experimental) (0.5.14)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain>=0.0.308->langchain_experimental) (1.33)\nRequirement already satisfied: langsmith<0.1.0,>=0.0.63 in /opt/conda/lib/python3.10/site-packages (from langchain>=0.0.308->langchain_experimental) (0.0.66)\nRequirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain>=0.0.308->langchain_experimental) (1.10.12)\nRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain>=0.0.308->langchain_experimental) (2.31.0)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain>=0.0.308->langchain_experimental) (8.2.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.308->langchain_experimental) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.308->langchain_experimental) (3.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.308->langchain_experimental) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.308->langchain_experimental) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.308->langchain_experimental) (1.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.308->langchain_experimental) (1.3.1)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<4.0->langchain>=0.0.308->langchain_experimental) (3.4)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<4.0->langchain>=0.0.308->langchain_experimental) (1.3.0)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio<4.0->langchain>=0.0.308->langchain_experimental) (1.1.3)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain>=0.0.308->langchain_experimental) (3.20.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain>=0.0.308->langchain_experimental) (0.9.0)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain>=0.0.308->langchain_experimental) (2.0)\nRequirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain>=0.0.308->langchain_experimental) (4.5.0)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain>=0.0.308->langchain_experimental) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain>=0.0.308->langchain_experimental) (2023.7.22)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain>=0.0.308->langchain_experimental) (2.0.2)\nRequirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain>=0.0.308->langchain_experimental) (21.3)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain>=0.0.308->langchain_experimental) (1.0.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=17.0->marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain>=0.0.308->langchain_experimental) (3.0.9)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## LangChain - Prompts","metadata":{}},{"cell_type":"code","source":"from langchain.prompts import PromptTemplate\n\nmeals = [\n    \"Beef Enchiladas with Feta cheese. Mexican-Greek fusion\",\n    \"Chicken Flatbreads with red sauce. Italian-Mexican fusion\",\n    \"Veggie sweet potato quesadillas with vegan cheese\",\n    \"One-Pan Tortelonni bake with peppers and onions\",\n]\n\nPROMPT_TEMPLATE = \"\"\"Here is the description of a meal: \"{meal}\".\n\nEmbed the meal into the given text: \"{text_to_personalize}\".\n\nPrepend a personalized message including the user's name \"{user}\" \n    and their preference \"{preference}\".\n\nMake it sound good.\n\"\"\"\n\nPROMPT = PromptTemplate(\n    input_variables=[\"meal\", \"text_to_personalize\", \"user\", \"preference\"],\n    template=PROMPT_TEMPLATE,\n)\n\nimport langchain_experimental.rl_chain as rl_chain\nchain = rl_chain.PickBest.from_llm(llm=llm, prompt=PROMPT)\n\nresponse = chain.run(\n    meal=rl_chain.ToSelectFrom(meals),\n    user=rl_chain.BasedOn(\"Tom\"),\n    preference=rl_chain.BasedOn([\"Vegetarian\", \"regular dairy is ok\"]),\n    text_to_personalize=\"This is the weeks specialty dish, our master chefs \\\n        believe you will love it!\",\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-22T19:21:52.184468Z","iopub.execute_input":"2023-11-22T19:21:52.184836Z","iopub.status.idle":"2023-11-22T19:22:15.484736Z","shell.execute_reply.started":"2023-11-22T19:21:52.184807Z","shell.execute_reply":"2023-11-22T19:22:15.483826Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stderr","text":"2023-11-22 19:22:15,480 - langchain_experimental.rl_chain.base - INFO - The selection scorer was not able to score,                 and the chain was not able to adjust to this response, error: The auto selection scorer did not manage to score the response, there is always the option to try again or tweak the reward prompt. Error: could not convert string to float: \"System: Based on the provided information, I would rank this text as a 0.7 out of 1 float. The text does not align well with the user's preference for vegetarian options, as it contains chicken, which is not vegetarian.\"\n","output_type":"stream"}]},{"cell_type":"code","source":"print(response[\"response\"])","metadata":{"execution":{"iopub.status.busy":"2023-11-22T19:22:15.486304Z","iopub.execute_input":"2023-11-22T19:22:15.486625Z","iopub.status.idle":"2023-11-22T19:22:15.491633Z","shell.execute_reply.started":"2023-11-22T19:22:15.486597Z","shell.execute_reply":"2023-11-22T19:22:15.490660Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"```\nThis is the week's specialty dish, Tom! Our master chefs believe you will love it! 😍 Chicken Flatbreads with red sauce, an Italian-Mexican fusion that combines the best of both worlds. 🌮👌 Whether you prefer ['Vegetarian','regular dairy is ok'], we have something for everyone! Come try it out and let us know what you think! 🤗 #FusionCuisine #ItalianMexican #ChickenFlatbreads #RedSauce #VegetarianOption #DairyOkay\n```\n\nExpected output:\n\n```\nThis is the week's specialty dish, Tom! Our master chefs believe you will love it! 😍 Chicken Flatbreads with red sauce, an Italian-Mexican fusion that combines the best of both worlds. 🌮👌 Whether you prefer ['Vegetarian','regular dairy is ok'], we have something for everyone! Come try it out and let us know what you think! 🤗 #FusionCuisine #ItalianMexican #ChickenFlatbreads #RedSauce #VegetarianOption #DairyOkay\n```\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install llama-index\n!pip install llama-hub","metadata":{"id":"zhfyqtJbNT7V","execution":{"iopub.status.busy":"2023-11-22T14:58:29.000725Z","iopub.execute_input":"2023-11-22T14:58:29.001017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LlamaIndex","metadata":{"id":"_jQWgxhaNT7V"}},{"cell_type":"code","source":"# https://llamahub.ai/\n\nfrom llama_index import download_loader\nimport os\n\n## LLM Connected to GMail\nGmailReader = download_loader('GmailReader')\nloader = GmailReader(query=\"from: me label:inbox\")\ndocuments = loader.load_data()\n\n## LLM Connected to Google Calendar\nGoogleCalendarReader = download_loader('GoogleCalendarReader')\nloader = GoogleCalendarReader()\ndocuments = loader.load_data()\n\n\n## LLM Connected to ASANA\nAsanaReader = download_loader('AsanaReader')\nreader = AsanaReader(\"<ASANA_TOKEN\">)\ndocuments = reader.load_data(workspace_id=\"<WORKSPACE_ID\">)\n\n\n## LLM Connected to Confluence\nfrom llama_hub.confluence.base import ConfluenceReader\n\ntoken = {\n    access_token: \"<access_token>\",\n    token_type: \"<token_type>\"\n}\noauth2_dict = {\n    \"client_id\": \"<client_id>\",\n    \"token\": token\n}\nbase_url = \"https://yoursite.atlassian.com/wiki\"\npage_ids = [\"<page_id_1>\", \"<page_id_2>\", \"<page_id_3\"]\nspace_key = \"<space_key>\"\nreader = ConfluenceReader(base_url=base_url, oauth2=oauth2_dict)\ndocuments = reader.load_data(space_key=space_key, include_attachments=True, page_status=\"current\")\ndocuments.extend(reader.load_data(page_ids=page_ids, include_children=True, include_attachments=True))\n\n## LLM Connected to Code Interpreter\nfrom llama_hub.tools.tool_spec.code_interpreter.base import CodeInterpreterToolSpec\nfrom llama_index.agent import OpenAIAgent\ncode_spec = CodeInterpreterToolSpec()\nagent = OpenAIAgent.from_tools(code_spec.to_tool_list())\n# Prime the agent to use the tool\nagent.chat('Can you help me write some python code to pass to the code_interpreter tool')\nagent.chat('write a python function to calculate volume of a sphere with radius 4.3cm')\n\n\n\nfrom llama_hub.tools.database.base import DatabaseToolSpec #Uses SQLAlchemy under the hood\nfrom llama_index.agent import OpenAIAgent\n\ndb_tools = DatabaseToolSpec(\n    scheme = \"postgresql\", # Database Scheme\n    host = \"localhost\", # Database Host\n    port = \"5432\", # Database Port\n    user = \"postgres\", # Database User\n    password = \"FakeExamplePassword\", # Database Password\n    dbname = \"postgres\", # Database Name\n)\nagent = OpenAIAgent.from_tools(db_tools.to_tool_list())\n\nagent.chat('What tables does this database contain')\nagent.chat('Describe the first table')\nagent.chat('Retrieve the first row of that table')\n\n\n## LLM Connected to Github Repo\nimport pickle\nimport os\n\nfrom llama_index import download_loader, GPTVectorStoreIndex\ndownload_loader(\"GithubRepositoryReader\")\n\nfrom llama_hub.github_repo import GithubClient, GithubRepositoryReader\n\ndocs = None\nif os.path.exists(\"docs.pkl\"):\n    with open(\"docs.pkl\", \"rb\") as f:\n        docs = pickle.load(f)\n\nif docs is None:\n    github_client = GithubClient(os.getenv(\"GITHUB_TOKEN\"))\n    loader = GithubRepositoryReader(\n        github_client,\n        owner =                  \"jerryjliu\",\n        repo =                   \"llama_index\",\n        filter_directories =     ([\"gpt_index\", \"docs\"], GithubRepositoryReader.FilterType.INCLUDE),\n        filter_file_extensions = ([\".py\"], GithubRepositoryReader.FilterType.INCLUDE),\n        verbose =                True,\n        concurrent_requests =    10,\n    )\n\n    docs = loader.load_data(branch=\"main\")\n\n    with open(\"docs.pkl\", \"wb\") as f:\n        pickle.dump(docs, f)\n\nindex = GPTVectorStoreIndex.from_documents(docs)\n\nquery_engine = index.as_query_engine()\nresponse = query_engine.query(\"Explain each LlamaIndex class?\")\nprint(response)\n\n\nfrom llama_hub.tools.salesforce.base import SalesforceToolSpec\n\n# Initialize the tool with your Salesforce credentials and other relevant details\nsf = SalesforceToolSpec(\n    username=sf_username,\n    password=sf_password,\n    consumer_key=sf_consumer_key,\n    consumer_secret=sf_consumer_secret,\n    domain=\"test\",\n)\n\nagent = OpenAIAgent.from_tools(\n    sf.to_tool_list(),\n    llm=llm,\n    verbose=True,\n    system_prompt=system_prompt,\n    memory=memory,\n)\n\nagent.chat(\"List 3 Accounts in Salesforce\")\nagent.chat(\"Provide information on a customer account John Doe\")\n\n\nfrom llama_hub.tools.slack.base import SlackToolSpec\nfrom llama_index.agent import OpenAIAgent\n\ntool_spec = SlackToolSpec(slack_token='token')\n\nagent = OpenAIAgent.from_tools(tool_spec.to_tool_list())\n\nagent.chat('What is the most recent message in the annoucements channel?')","metadata":{"id":"j-zPnsNaNT7V","trusted":true},"execution_count":null,"outputs":[]}]}